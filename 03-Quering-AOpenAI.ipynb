{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d59d527f-1100-45ff-b051-5f7c9029d94d",
   "metadata": {},
   "source": [
    "# Queries with and without Azure OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f6c7e3-9037-4b1e-ae17-1deaa27b9c08",
   "metadata": {},
   "source": [
    "## Set up variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e50b404-a061-49e7-a3c7-c6eabc98ff0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import requests\n",
    "from collections import OrderedDict\n",
    "from IPython.display import display, HTML\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "from app.embeddings import OpenAIEmbeddings\n",
    "from app.prompts import STUFF_PROMPT, REFINE_PROMPT, REFINE_QUESTION_PROMPT\n",
    "from app.credentials import (\n",
    "    DATASOURCE_CONNECTION_STRING,\n",
    "    AZURE_SEARCH_API_VERSION,\n",
    "    AZURE_SEARCH_ENDPOINT,\n",
    "    AZURE_SEARCH_KEY,\n",
    "    COG_SERVICES_NAME,\n",
    "    COG_SERVICES_KEY,\n",
    "    AZURE_OPENAI_ENDPOINT,\n",
    "    AZURE_OPENAI_KEY,\n",
    "    AZURE_OPENAI_API_VERSION\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f2c22f8-79ab-405c-95e8-77a1978e53bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the Payloads header\n",
    "headers = {'Content-Type': 'application/json','api-key': AZURE_SEARCH_KEY}\n",
    "params = {'api-version': AZURE_SEARCH_API_VERSION}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9297d29b-1f61-4dce-858e-bf4272172dba",
   "metadata": {},
   "source": [
    "## Multi-Index Search queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a46e2d3-298a-4708-83de-9e108b1a117a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Index that we are going to query (from Notebook 01 and 02)\n",
    "index1_name = \"cogsrch-snowflake-index-files\"\n",
    "indexes = [index1_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9b53c14-19bd-451f-aa43-7ad27ccfeead",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION = \"What is Snowflake?\" \n",
    "# This questions is interesting since CLP means something in Computer science and means something different in medical field "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faf2e30f-e71f-4533-ab52-27d048b80a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://azure-cog-search-g2ysbgn5zpihq.search.windows.net/indexes/cogsrch-snowflake-index-files/docs?api-version=2021-04-30-Preview&search=What is Snowflake?&select=*&$top=10&queryLanguage=en-us&queryType=semantic&semanticConfiguration=my-semantic-config&$count=true&speller=lexicon&answers=extractive|count-3&captions=extractive|highlight-false\n",
      "200\n",
      "Results Found: 3, Results Returned: 3\n"
     ]
    }
   ],
   "source": [
    "agg_search_results = []\n",
    "\n",
    "for index in indexes:\n",
    "    url = AZURE_SEARCH_ENDPOINT + '/indexes/'+ index + '/docs'\n",
    "    url += '?api-version={}'.format(AZURE_SEARCH_API_VERSION)\n",
    "    url += '&search={}'.format(QUESTION)\n",
    "    url += '&select=*'\n",
    "    url += '&$top=10'  # You can change this to anything you need/want\n",
    "    url += '&queryLanguage=en-us'\n",
    "    url += '&queryType=semantic'\n",
    "    url += '&semanticConfiguration=my-semantic-config'\n",
    "    url += '&$count=true'\n",
    "    url += '&speller=lexicon'\n",
    "    url += '&answers=extractive|count-3'\n",
    "    url += '&captions=extractive|highlight-false'\n",
    "\n",
    "    resp = requests.get(url, headers=headers)\n",
    "    print(url)\n",
    "    print(resp.status_code)\n",
    "\n",
    "    search_results = resp.json()\n",
    "    #print(search_results)\n",
    "    agg_search_results.append(search_results)\n",
    "    print(\"Results Found: {}, Results Returned: {}\".format(search_results['@odata.count'], len(search_results['value'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fd0fe5-4ee0-42e2-a920-72b93a407389",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Display the top results (from both searches) based on the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e938337-602d-4b61-8141-b8c92a5d91da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Top Answers</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5>Answer - score: 0.99560546875</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Snowflake is a   massively parallel processing (MPP) database that   is fully relational, ACID compliant, and processes   standard SQL natively without translation or   simulation. It was designed as a software service that   can take full advantage of cloud infrastructure, while   retaining the positive attributes of existing solutions."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5>Answer - score: 0.90380859375</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Snowflake provides out-of-the-box network access control via “network policies”, allowing users to restrict   account access to specific IP addresses. The level of granularity can be account-level and user-specific   (bear in mind that user settings take precedence when you assign policies for both)."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Top Results</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5>19336_Preview&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;score: 2.0341796875</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Snowflake provides out-of-the-box network access control via “network policies”, allowing users to restrict   account access to specific IP addresses. The level of granularity can be account-level and user-specific   (bear in mind that user settings take precedence when you assign policies for both)."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5>Untitled&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;score: 1.86328125</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Snowflake is a   massively parallel processing (MPP) database that   is fully relational, ACID compliant, and processes   standard SQL natively without translation or   simulation. It was designed as a software service that   can take full advantage of cloud infrastructure, while   retaining the positive attributes of existing solutions."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5>None&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;score: 1.4697265625</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "1  the snowflake elastic data warehouse sigmod 2016 and beyond  ashish motivala, jiaqi yan        2  our product  •the snowflake elastic data warehouse, or “snowflake” •built for the cloud •multi-tenant, transactional, secure, highly scalable, elastic •implemented from scratch (no hadoop, postgres etc.)  •currently runs on aws and azure  •serves …"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML('<h4>Top Answers</h4>'))\n",
    "#print(agg_search_results[0])\n",
    "for search_results in agg_search_results:\n",
    "    for result in search_results['@search.answers']:\n",
    "        if result['score'] > 0.5: # Show answers that are at least 50% of the max possible score=1\n",
    "            display(HTML('<h5>' + 'Answer - score: ' + str(result['score']) + '</h5>'))\n",
    "            display(HTML(result['text']))\n",
    "            \n",
    "print(\"\\n\\n\")\n",
    "display(HTML('<h4>Top Results</h4>'))\n",
    "\n",
    "file_content = OrderedDict()\n",
    "\n",
    "for search_results in agg_search_results:\n",
    "    for result in search_results['value']:\n",
    "        if result['@search.rerankerScore'] > 0.4: # Show results that are at least 10% of the max possible score=4\n",
    "            display(HTML('<h5>' + str(result['title']) + '&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;score: '+ str(result['@search.rerankerScore']) + '</h5>'))\n",
    "            display(HTML(result['@search.captions'][0]['text']))\n",
    "            file_content[result['id']]={\n",
    "                                    \"title\": result['title'],\n",
    "                                    \"chunks\": result['pages'],\n",
    "                                    \"language\": result['language'], \n",
    "                                    \"caption\": result['@search.captions'][0]['text'],\n",
    "                                    \"score\": result['@search.rerankerScore'],\n",
    "                                    \"location\": result['metadata_storage_path']                  \n",
    "                                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eea62a7d-7e0e-4a93-a89c-20c96560c665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
    "os.environ[\"OPENAI_API_BASE\"] = os.environ[\"AZURE_OPENAI_ENDPOINT\"] = AZURE_OPENAI_ENDPOINT\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ[\"AZURE_OPENAI_API_KEY\"] = AZURE_OPENAI_KEY\n",
    "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"] = AZURE_OPENAI_API_VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f7b41d2-65b0-4058-8a46-c76cf6960720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 30\n"
     ]
    }
   ],
   "source": [
    "docs = []\n",
    "for key,value in file_content.items():\n",
    "    for page in value[\"chunks\"]:\n",
    "        docs.append(Document(page_content=page, metadata={\"source\": value[\"location\"]}))\n",
    "        \n",
    "print(\"Number of chunks:\",len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24226dd4-6980-49e8-89dd-5f9f6abbfead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the Embedder model\n",
    "if len(docs) < 50:\n",
    "    # OpenAI models are accurate but slower\n",
    "    embedder = OpenAIEmbeddings(document_model_name=\"text-embedding-ada-002\", query_model_name=\"text-embedding-ada-002\") \n",
    "else:\n",
    "    # Bert based models are faster (3x-10x) but not as great in accuracy as OpenAI models\n",
    "    # Since this repo supports Multiple languages we need to use a multilingual model. \n",
    "    # But if English only is the requirement, use \"multi-qa-MiniLM-L6-cos-v1\"\n",
    "    # The fastest english model is \"all-MiniLM-L12-v2\"\n",
    "    if random.choice(list(file_content.items()))[1][\"language\"] == \"en\":\n",
    "        embedder = HuggingFaceEmbeddings(model_name = 'multi-qa-MiniLM-L6-cos-v1')\n",
    "    else:\n",
    "        embedder = HuggingFaceEmbeddings(model_name = 'distiluse-base-multilingual-cased-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5cc7ae5-6fe9-4fd8-992d-0507297387ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAIEmbeddings(client=<class 'openai.api_resources.embedding.Embedding'>, document_model_name='text-embedding-ada-002', query_model_name='text-embedding-ada-002', openai_api_key=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31e85122-824a-42ea-bb32-ad981309dc9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 129 ms, sys: 24.7 ms, total: 154 ms\n",
      "Wall time: 1.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if(len(docs)>1):\n",
    "    db = FAISS.from_documents(docs, embedder)\n",
    "else:\n",
    "    print(\"No results Found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57429335-34d3-458a-b7c9-52482a0936d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_db = db.similarity_search(QUESTION, k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "634f5bd8-0d56-47b8-84fd-fe9b678bfc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "# Make sure you have the deployment named \"gpt-35-turbo\" for the model \"gpt-35-turbo (0301)\". \n",
    "# Use \"gpt-4\" if you have it available.\n",
    "llm = AzureChatOpenAI(deployment_name=\"gpt-35-turbo\", temperature=0.9, max_tokens=500)\n",
    "chain = load_qa_with_sources_chain(llm, chain_type=\"map_reduce\", return_intermediate_steps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1e619b8-1dcf-431b-8aad-f1696a09c2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2106 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 674 ms, sys: 95.7 ms, total: 770 ms\n",
      "Wall time: 23.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = chain({\"input_documents\": docs_db, \"question\": QUESTION}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cddb1cb-a4a0-4e2f-9f0c-4216b0f232b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Azure OpenAI ChatGPT Answer:</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snowflake is an enterprise-ready data warehouse as a service that is built for the cloud, highly elastic, and available, providing semi-structured and schema-less data at the speed of relational data on AWS and Azure. It has a multi-cluster, shared-data architecture, and supports self-describing, compact binary serialization, with a huge metadata layer. Snowflake is a game changer for an organization with a low load time and high load frequency. It is built on a SaaS model and has a rapidly growing user base and data volume, of over 1000 active customers serving tens of millions of queries per day over hundreds petabytes of data. It is a patent-pending new architecture that delivers the power of data warehousing, the flexibility of big data platforms, and the elasticity of the cloud, all at a fraction of the cost of traditional solutions. \n",
      "\n",
      "Sources:\n",
      "[' https://depprocureformstorage.blob.core.windows.net/snowflake-data/Snowflake%20Internals.pdf', ' https://depprocureformstorage.blob.core.windows.net/snowflake-data/Snowflake_basic%20overview.pdf']\n"
     ]
    }
   ],
   "source": [
    "answer = response['output_text']\n",
    "#print(answer)\n",
    "display(HTML('<h4>Azure OpenAI ChatGPT Answer:</h4>'))\n",
    "\n",
    "print(answer.split(\"SOURCES:\")[0])\n",
    "print(\"Sources:\")\n",
    "print(answer.split(\"SOURCES:\")[1].replace(' ',' ').split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11345374-6420-4b36-b061-795d2a804c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Snowflake is an enterprise-ready data warehouse as a service, with a novel multi-cluster, shared-data architecture. It is highly elastic and available, and provides semi-structured and schema-less data at the speed of relational data. Snowflake offers a pure SaaS experience and has a rapidly growing user base and data volume.',\n",
       " '• The Snowflake Elastic Data Warehouse, or “Snowflake”\\n• Built for the cloud\\n• Multi-tenant, transactional, secure, highly scalable, elastic\\n• Implemented from scratch (no Hadoop, Postgres etc.)\\n• Currently runs on AWS and Azure \\n• Serves tens of millions of queries per day over hundreds \\npetabytes of data\\n• 1000+ active customers, growing fast',\n",
       " 'Snowflake is an enterprise data warehouse as a cloud service that supports self-describing, compact binary serialization and is designed for fast key-value lookup, comparison, and hashing. It is supported by all SQL operators (joins, group by, sort...). Snowflake also introduces automatic type inference and columnar storage for schema-less data (VARIANT). It offers automatic columnarization of semi-structured data and ELT with speed and expressiveness of RDBMS. Snowflake also has features like time travel and cloning, security, data sharing, serverless ingestion of data, and support for Azure Cloud. It is a multi-cluster, shared-data architecture game changer for an organization with a low load time and high load frequency. Snowflake is built on a SaaS model and has a huge metadata layer. It has a lot of ongoing challenges like supporting tens of thousands of concurrent users, and lots of future work like advisors, data lake support, streaming, and replication.',\n",
       " \"Snowflake is a cloud data warehousing company that has reinvented the data warehouse for the cloud and today's data. It has a patent-pending new architecture that delivers the power of data warehousing, the flexibility of big data platforms, and the elasticity of the cloud, all at a fraction of the cost of traditional solutions.\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment if you want to inspect the results from each top similar chunk (k=4 by default)\n",
    "response['intermediate_steps']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f347373a-a5be-473d-b64e-0f6b6dbcd0e0",
   "metadata": {},
   "source": [
    "# Summary\n",
    "##### This answer is way better than taking just the result from Azure Cognitive Search. So the summary is:\n",
    "- Azure Cognitive Search give us the top results (context)\n",
    "- Azure OpenAI takes these results and understand the content and uses it as context to give the best answer\n",
    "- Best of two worlds!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d22f6d6-642d-497a-a079-721127e277c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
